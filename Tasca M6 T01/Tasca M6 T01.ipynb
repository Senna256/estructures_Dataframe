{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tasca M6 T01 Enric Sena Alvarez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af36fce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "# Exercici 1\n",
    "#Crea almenys dos models de regressió diferents per intentar predir el millor possible el preu de les vivendes (MEDV) de l'arxiu adjunt.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#importo les dades:\n",
    "dades = pd.read_csv(\"housing_data.csv\")\n",
    "dades.columns=[\"CRIM\",\"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PTRATIO\",\"B\",\"LSTAT\",\"MEDV\"]\n",
    "dades.head(10)\n",
    "\n",
    "\n",
    "#Separo les dades en train i test:\n",
    "X=dades.drop('MEDV',axis=1)\n",
    "Y=dades.MEDV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5703549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.04 degrees.\n",
      "Accuracy: 90.83 %\n"
     ]
    }
   ],
   "source": [
    "#random forest regression:\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf=RandomForestRegressor(n_estimators=1000,random_state=42)\n",
    "rf.fit(X_train,Y_train)\n",
    "\n",
    "predictions=rf.predict(X_test)\n",
    "errors=abs(predictions-Y_test)\n",
    "\n",
    "mape=100*(errors/Y_test)\n",
    "accuracy=100-np.mean(mape)\n",
    "print('Mean Absolute Error:',round(np.mean(errors),2),'degrees.')\n",
    "print('Accuracy:',round(accuracy,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6abb5742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: LSTAT                Importance: 0.5\n",
      "Variable: RM                   Importance: 0.3\n",
      "Variable: DIS                  Importance: 0.07\n",
      "Variable: CRIM                 Importance: 0.04\n",
      "Variable: NOX                  Importance: 0.03\n",
      "Variable: AGE                  Importance: 0.02\n",
      "Variable: INDUS                Importance: 0.01\n",
      "Variable: TAX                  Importance: 0.01\n",
      "Variable: PTRATIO              Importance: 0.01\n",
      "Variable: B                    Importance: 0.01\n",
      "Variable: ZN                   Importance: 0.0\n",
      "Variable: CHAS                 Importance: 0.0\n",
      "Variable: RAD                  Importance: 0.0\n",
      "Mean Absolute Error: 3.04 degrees.\n",
      "Accuracy: 85.29 %.\n"
     ]
    }
   ],
   "source": [
    "# 2n model: random forest amb només les variables importants:\n",
    "X_list=list(X.columns)\n",
    "importances=list(rf.feature_importances_)\n",
    "X_importances=[(X,round(importances,2)) for X, importances in zip(X_list,importances)]\n",
    "\n",
    "X_importances=sorted(X_importances,key=lambda x: x[1],reverse=True)\n",
    "\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in X_importances];\n",
    "\n",
    "\n",
    "#em quedo només amb LSTAT i RM\n",
    "\n",
    "\n",
    "rf_most_important=RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "\n",
    "train_important=X_train[['LSTAT','RM']]\n",
    "test_important=X_test[['LSTAT','RM']]\n",
    "\n",
    "rf_most_important.fit(train_important,Y_train)\n",
    "predictions=rf_most_important.predict(test_important)\n",
    "\n",
    "errors=abs(predictions-Y_test)\n",
    "\n",
    "print('Mean Absolute Error:',round(np.mean(errors),2),'degrees.')\n",
    "mape=np.mean(100*errors/Y_test)\n",
    "accuracy=100-mape\n",
    "print('Accuracy:',round(accuracy,2),'%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8cb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercici 2: Compara'ls en base al MSE i R^2\n",
    "#En el 1r model he obtingut un accuracy de 90.83% (no és l'R quadrat però al ser un model fet amb random forest considero una millor mètrica per avaluar-lo, usar l'accuracy)\n",
    "#En el 2n model he usat només les 2 variables més importants i he obtingut un accuracy de 85.29%. Considero que és un model acceptable ja que compleix amnb el principi de parsimònia ja que tan sols amb dues variables, obtenim quasi al 100% la precisió que obtenim amb el model amb totes les variables i per tant més complexe computacionalment.\n",
    "\n",
    "#En quant al MSE. segueix sortint millor el 1r model pel fet que hem dit abans, al contenir moltes més varaibles. per poc que aportin ja sumen més informació que les 2 del model 2n i per tant podem reduir l'error quadràtic mitjà.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f7c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercici 3\n",
    "#Fet al exercici 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b312bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercici 4\n",
    "# Usant validació interna obtenim els valors comentats al exercici 2 en quant a l'accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c8688657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.13 degrees.\n",
      "Accuracy: 99.39 %\n"
     ]
    }
   ],
   "source": [
    "#Exercici 5: No utilitzis RM per fer prediccions.\n",
    "\n",
    "\n",
    "#Faig el model complet sense RM:\n",
    "X=dades.drop('MEDV',axis=1)\n",
    "X=dades.drop('RM',axis=1)\n",
    "Y=dades.MEDV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf=RandomForestRegressor(n_estimators=1000,random_state=42)\n",
    "rf.fit(X_train,Y_train)\n",
    "\n",
    "predictions=rf.predict(X_test)\n",
    "errors=abs(predictions-Y_test)\n",
    "\n",
    "mape=100*(errors/Y_test)\n",
    "accuracy=100-np.mean(mape)\n",
    "print('Mean Absolute Error:',round(np.mean(errors),2),'degrees.')\n",
    "print('Accuracy:',round(accuracy,2),'%')\n",
    "\n",
    "#Veiem que el model millora molt respecte als 2 anteriors. Això ens pot portar a pensar que la variable RM és confusora i per tant només recull informació implicita en altrea variables i per això sortia com a la 2a més important quan en veritat hem vist que eliminant-la del model, aquest prediu bé el 99.39% dels casos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
